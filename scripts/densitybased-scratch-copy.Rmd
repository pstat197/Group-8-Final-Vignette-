---
title: "density-based scratch copy"
author: "Ruoxin Wang"
date: "2022-12-04"
output: html_document
---
# Density-based clustering

[<https://developers.google.com/machine-learning/clustering/clustering-algorithms> <https://www.datanovia.com/en/lessons/dbscan-density-based-clustering-essentials/>]

Unlike the other two algorithms that mainly derive from the how computer calculated the clusters, the basic idea behind the density-based clustering approach is derived from a human intuitive clustering method. It means that the results of clustering calculated from a density-based method would be similar to how people classify the clusters through graphs only based on their eyes. For example, looking at the figure below, it is easy for us to identify the different clusters only based on our eyes because of the various dense regions of points on the graph.

![](images/dbscan-idea-01.png)

## DBSCAN algorithm

DBSCAN ,or "Density-Based Spatial Clustering of Applications with Noise", is a commonly used unsupervised clustering Machine Learning algorithm for density-based clustering approach. The idea it uses are density reachability and connectivity. The data would be divided into clusters with similar characteristics. However, unlike the hierarchical clustering, the number of clusters do not needed to be specified in advance. A cluster is defined as a maximum set of densely connected points. It discovers clusters of arbitrary shapes in spatial databases with noise.

[<https://www.geeksforgeeks.org/dbscan-clustering-in-r-programming/>]

## Important concepts

![](images/dbscan-concept.png)

Two required parameters in the DBSCAN algorithm are:

[<https://towardsdatascience.com/explaining-dbscan-clustering-18eaf5c83b31>

<http://www.sefidian.com/2020/12/18/how-to-determine-epsilon-and-minpts-parameters-of-dbscan-clustering/>]

-   *eps* : Eps stands for "Epsilon", which stands for the maximum radius of the neighborhood or the clusters, and is shown as the blue line in the above figure. The data points will be included in the clusters if their mutual distance is less than or equal to the value of epsilon. For the DBSCAN algorithm, larger eps will create broader clusters, which contains more data points; smaller eps will narrow clusters, which contains less data points. However, if eps is chosen too small for the dataset, a large part of the data points would be considered as the noise points and not be included in the clusters; if eps is chosen too large for the dataset, clusters will be merged and the majority of the data points will be included in one same cluster.

-   *MinPts*: MinPts stands for "the minimum number of data points contains within the radius of a neighborhood" to be considered as a cluster, which is the value of 4 in the above figure. In the DBSCAN algorithm, the value MinPts should be at least 3 to be used as a valid value. A smaller value of MinPts used, more clusters and more outliers will be produced; a larger value of MinPts used, more robust clusters will be created.

By changing the above two hyperparameter, the result of clustering may be varied.

Other important terms to understand how DBSCAN works are:

[<https://www.dominodatalab.com/blog/topology-and-density-based-clustering>]

-   *Core points*: 
-   *Border points*:
-   *Noise points/ Outliers*:


```{r}
#install.packages("fpc")
#install.packages("dbscan")
#install.packages("factoextra")
```

### Determining eps: Elbow Method
[https://towardsdatascience.com/explaining-dbscan-clustering-18eaf5c83b31]

In the DBSCAN algorithm, the best eps value is commonly found with a k-distance graph, where the value of k should equal to the value of MinPts. For this graph, x-axis contains all data points in the dataset and y-axis stands for the average distances of the data points. The best eps may chosen by looking at the elbow of the k-distance line. For example, after scaling our data, it plots a k-distance graph with a k value of 5 below. From this plot, if we choose MinPts equal to 5, the value of eps should be between 2 to 4.

```{r}
scale.df <- df %>% scale()
df.matrix <- as.matrix(scale.df)
kNNdistplot(df.matrix, k=5)
abline(h=2.5, col="red")
```

### Determining MinPts
- Approach 1: 
- Approach 2: 

## Map clusters

### eps = 0.5, MinPts = 18

```{r}
set.seed(1)
db <- fpc::dbscan(scale.df, eps = 0.5, MinPts = 18)

fviz_cluster(db, data = scale.df, stand = FALSE,
             ellipse = FALSE, show.clust.cent = FALSE,
             geom = "point",palette = "jco", ggtheme = theme_classic())
```

### eps = 3, MinPts = 5

```{r}
set.seed(1)
db <- dbscan(scale.df, eps = 3, MinPts = 5)

fviz_cluster(db, data = scale.df, stand = FALSE,
             ellipse = FALSE, show.clust.cent = FALSE,
             geom = "point",palette = "jco", ggtheme = theme_classic())
```

### eps = 6, MinPts = 5

```{r}
set.seed(1)
db <- fpc::dbscan(scale.df, eps = 6, MinPts = 5)

fviz_cluster(db, data = scale.df, stand = FALSE,
             ellipse = FALSE, show.clust.cent = FALSE,
             geom = "point",palette = "jco", ggtheme = theme_classic())
```

### eps = 3, MinPts = 10

```{r}
set.seed(1)
db <- fpc::dbscan(scale.df, eps = 3, MinPts = 10)

fviz_cluster(db, data = scale.df, stand = FALSE,
             ellipse = FALSE, show.clust.cent = FALSE,
             geom = "point",palette = "jco", ggtheme = theme_classic())
```

### Check PCA

```{r}
# check PCA
pr.out <- prcomp(scale.df,
                 scale =TRUE,
                 center = TRUE)

plot(pr.out$x[,1], pr.out$x[,2],
     xlab = 'PC1', ylab = 'PC2')
```

[PCA got a dense single group may be why we only got one cluster in DBscan. ref: <https://stackoverflow.com/questions/48051800/why-dbscan-clustering-returns-single-cluster-on-movie-lens-data-set>]

```{r, out.width='150%'}
# add country names to clusters
db_clust <- db$cluster
names(db_clust) <- row.names(df)

# plot map clusters
db_clust %>%
  clust_to_df() %>%
  rename_countries() %>%
  plot_map()
```